{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d093f7d-e2a8-4f17-83c8-637c3744c67d",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9e2eda2-d96a-49a2-a912-41441c0e27d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04971e91-b735-4555-a4bd-88d004f258ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Payoff matrices for Player A and Player B\n",
    "payoffs = {\n",
    "    \"A\": np.array([[3, 0], [5, 1]]), \n",
    "    \"B\": np.array([[3, 5], [0, 1]])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cba5fba0-4fd9-4033-ad30-b5e6a94d6fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-tables for both players\n",
    "Q_A = np.zeros((2, 1))  \n",
    "Q_B = np.zeros((2, 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76d23e22-f0c9-4046-ad30-b2ae897d8ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-learning parameters\n",
    "alpha = 0.8  # Learning rate\n",
    "gamma_A = 0.99  # Discount factor of A\n",
    "gamma_B = 0.99  # Discount factor of B\n",
    "epsilon = 0.6  # Exploration rate\n",
    "min_epsilon = 0.01  # Minimum exploration rate\n",
    "decay_rate = 0.1  # Decay rate for epsilon\n",
    "\n",
    "# Simulation parameters\n",
    "episodes = 1500000\n",
    "\n",
    "# One-state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6edcc0f3-1b6b-4eee-8415-fafeabb31f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track simulations result regarding cooperation rates\n",
    "track_cooperation = []  \n",
    "coop_A_count = 0\n",
    "coop_B_count = 0\n",
    "\n",
    "decay_alert = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac2b8c2d-43ae-4c8f-98c3-fdcb8da9ef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for epsilon-greedy action selection\n",
    "def choose_action(Q_column, epsilon):\n",
    "    if np.random.rand() < epsilon:\n",
    "        # Random action (exploration)\n",
    "        return np.random.choice([0, 1])  # 0 = \"C\", 1 = \"D\"\n",
    "    else:\n",
    "        # Greedy action (exploitation)\n",
    "        max_actions = np.flatnonzero(Q_column == Q_column.max())\n",
    "        randomMaxAction = np.random.choice(max_actions)\n",
    "        return randomMaxAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3777e5bf-82f1-4b1b-bc09-2cc6f765edc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epsilon decay function\n",
    "def epsilon_decay(epsilon, min_epsilon, decay_rate, episode):\n",
    "    return max(min_epsilon, epsilon * np.exp(-decay_rate * episode))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d524e4-bf5d-4928-af80-a124e9a104dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop decaying at episode n° 9\n"
     ]
    }
   ],
   "source": [
    "# Run Q-learning\n",
    "for episode in range(1, episodes+1):\n",
    "    # Decay epsilon\n",
    "    epsilon = epsilon_decay(epsilon, min_epsilon, decay_rate, episode)\n",
    "\n",
    "    if epsilon == 0.01 and decay_alert == 0:\n",
    "        decay_alert += episode\n",
    "        print(\"Stop decaying at episode n°\", episode)\n",
    "    \n",
    "    # Choose actions\n",
    "    action_A = choose_action(Q_A, epsilon)\n",
    "    action_B = choose_action(Q_B, epsilon)\n",
    "\n",
    "    # Count cooperation\n",
    "    if action_A == 0:  \n",
    "        coop_A_count += 1\n",
    "    if action_B == 0:\n",
    "        coop_B_count += 1\n",
    "    \n",
    "    # Get rewards\n",
    "    reward_A = payoffs[\"A\"][action_A, action_B]\n",
    "    reward_B = payoffs[\"B\"][action_A, action_B]\n",
    "    \n",
    "    \n",
    "    # Update Q-tables\n",
    "    Q_A[action_A] += alpha * (reward_A + gamma_A * np.max(Q_A) - Q_A[action_A])\n",
    "    Q_B[action_B] += alpha * (reward_B + gamma_B * np.max(Q_B) - Q_B[action_B])\n",
    "\n",
    "    \n",
    "    # Track cooperation every 1000 episodes\n",
    "    if episode % 100000 == 0:\n",
    "        track_cooperation.append({\n",
    "            \"episode\": episode,\n",
    "            \"cooperation_A\": coop_A_count / 100000,\n",
    "            \"cooperation_B\": coop_B_count / 100000\n",
    "        })\n",
    "        coop_A_count = 0\n",
    "        coop_B_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a296ec-41a0-445c-af89-99d441f5e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert cooperation tracking to DataFrame\n",
    "track_cooperation_df = pd.DataFrame(track_cooperation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d246ae-596a-4d93-818c-1cd6ef676a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Q-tables\n",
    "print(\"Q-Table for Player A:\")\n",
    "print(Q_A)\n",
    "print(\"\\nQ-Table for Player B:\")\n",
    "print(Q_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cd2971-67c4-4966-ba0f-391cf215e559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cooperation rates\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.ylim(0, 1.1)\n",
    "plt.plot(track_cooperation_df[\"episode\"], track_cooperation_df[\"cooperation_A\"], label=\"Player A\", color=\"blue\")\n",
    "plt.plot(track_cooperation_df[\"episode\"], track_cooperation_df[\"cooperation_B\"], label=\"Player B\", color=\"red\")\n",
    "plt.title(\"Evolution of Cooperation in the Prisoner's Dilemma\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Cooperation Rate\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
